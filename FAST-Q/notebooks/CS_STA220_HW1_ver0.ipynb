{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='1-1'> STA220 HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1-1'> Chenghan Sun 915030521"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 220 Homework 1\n",
    "===========\n",
    "- Prof. James Sharpnack\n",
    "- Do not distribute\n",
    "\n",
    "You will be graded according to your ability to follow the instructions, maintain organized code, with docstrings on all defs.  You should focus on memory and time complexity, and do not read in more data than you need to.  Throughout this assignment you should be acting iteratively on the data and never read it all into RAM.  You can find the data in the following fastq file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head ../data/dummy.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fastq file is a way of encoding short genomic reads from high throughput sequencing technology, such as Illumina next generation sequencers.  It consists of\n",
    "\n",
    "1. A sequence identifier which for this sequencer starts with an @, then followed by a long name, and a length tag.\n",
    "2. The sequence (the base calls; A, C, T, G and N), N stands for not able to read, due to insufficient quality.\n",
    "3. A separator, which is simply a plus (+) sign, perhaps followed by the identifier.\n",
    "4. The base call quality scores. These are Phred +33 encoded, using ASCII characters to represent the numerical quality scores (more later).\n",
    "\n",
    "Each problem is worth equal number of points.  Modify all appropriate files in the directory structure (you should not need to add any new files).  Write up what you did below with additional cells in between the exercise cells, which you should leave in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Insert Code directory for the following exercises 2-8\n",
    "\"\"\"\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0, '../code/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__ Throughout this homework you should never read the full data into RAM.  You should be able to get practice only reading the data in sequence and not reading it into memory and manipulating it that way.  Do the following in code cells between Exercise 1 and 2.\n",
    "\n",
    "1. Write a short script that counts the number of lines in the file without loading the file in memory.\n",
    "2. Each new read begins with a sequence identifier that begins with \"@\", write a short script that counts the number of sequences.\n",
    "3. Write a def which replaces all \"T\"s to \"U\" (transcript DNA to RNA) in a sequence.\n",
    "4. Write a script that looks for any anomalous reads or junk in the data that doesn't follow the basic structure above.  Clean the data and document what you did below, add the script you used to find the anomalous lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This exercise was distributed into four parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(filename):\n",
    "    \"\"\" Summary: \n",
    "            Main function for Exercise 1.1\n",
    "            Counts the number of lines in the file without loading the file in memory.\n",
    "        Parameters:\n",
    "            filename: relative path of the text file\n",
    "        Returns:\n",
    "            num_lines: the number of lines in the file\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            num_lines = i+1\n",
    "    return num_lines\n",
    "\n",
    "filename = '../data/dummy.fastq'\n",
    "num_lines = file_len(filename)\n",
    "print(\"The number of lines in the file = \" + str(num_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_seq(filename, identifier):\n",
    "    \"\"\" Summary:\n",
    "            Main function for Exercise 1.2\n",
    "        Parameters:\n",
    "            filename: relative path of the text file\n",
    "            identifier: sequence start with notation \"@\"\n",
    "        Returns:\n",
    "            num_seqs: the number of sequences in the file\n",
    "    \"\"\"\n",
    "    num_seqs = 0\n",
    "    with open(filename) as f:\n",
    "        for lines in f:\n",
    "            target = lines.split()[0][0] # extarct the beginning text of each line\n",
    "            if identifier == target:\n",
    "                num_seqs = num_seqs+1\n",
    "    return num_seqs\n",
    "\n",
    "filename = '../data/dummy.fastq'\n",
    "identifier = '@'\n",
    "num_seqs = file_seq(filename, identifier)\n",
    "print(\"The number of sequences in the file = \" + str(num_seqs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: \n",
    "\n",
    "**Note**: Use the first sequence for function testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNA2RNA_seq(seq, replacements_dict):\n",
    "    \"\"\" Summary:\n",
    "            Main function for Exercise 1.3\n",
    "            Replaces all \"T\"s to \"U\" (transcript DNA to RNA) in a sequence\n",
    "        Parameters: \n",
    "            seq: sequence for modification \n",
    "            replacements_dict: dictionary for replacing information \n",
    "        Returns:\n",
    "            seq_t: transformed sequence \n",
    "    \"\"\"\n",
    "    for src, target in replacements_dict.items():\n",
    "        seq_t = seq.replace(src, target)\n",
    "    return seq_t\n",
    "\n",
    "replacements_dict = {'T':'U'}\n",
    "test_seq = \"NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\"\n",
    "seq_t = DNA2RNA_seq(test_seq, replacements_dict)\n",
    "print(\"The original sequence is: {}\".format(test_seq))\n",
    "print(\"The transformed sequence is: {}\".format(seq_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script that looks for any anomalous reads or junk in the data that doesn't follow the basic structure above. Clean the data and document what you did below, add the script you used to find the anomalous lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # use the regular expression pkg\n",
    "\n",
    "def check_file(filename, seq_pattern_dict, i=0):\n",
    "    \"\"\" Summary:\n",
    "            Part I: Main function for Exercise 1.4\n",
    "            Check anomalous reads or junk in the data\n",
    "        Parameters: \n",
    "            filename: relative path of the data file\n",
    "            seq_pattern_dict: defined dictionary contains regular expression of text lines\n",
    "            i: index of lines as line indicator, initialized to be 0\n",
    "        Returns:\n",
    "            printed information about anomalous reads or junk in the data\n",
    "    \"\"\"\n",
    "    with open(filename) as f: \n",
    "        for line in f:\n",
    "            flag = i%4 # flag as a indicator of line number (0,1,2,3) inside a sequence \n",
    "            pat = seq_pattern_dict[flag]\n",
    "            if pat.match(line):\n",
    "                i+=1\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Line {} is detected to be text exception.\".format(i))\n",
    "\n",
    "filename = '../data/dummy.fastq' # raw text file\n",
    "seq_pattern_1 = re.compile(\"^@[a-zA-Z0-9_.+-]+\\.[a-zA-Z0-9-.]+\\s[a-zA-Z0-9-.]+\\s[a-zA-Z0-9=]*$\") # re of 1st line\n",
    "seq_pattern_2 = re.compile(\"^[ACTGN]*$\") # re of 2ed line\n",
    "seq_pattern_3 = re.compile(\"^.+[a-zA-Z0-9_.+-]+\\.[a-zA-Z0-9-.]+\\s[a-zA-Z0-9-.]+\\s[a-zA-Z0-9=]*$\") # re of 3rd line\n",
    "seq_pattern_4 = re.compile(\"^[a-zA-Z0-9_.+-./.<.#]*$\") # re of 4th line\n",
    "\n",
    "seq_pattern_dict = {0:seq_pattern_1, 1:seq_pattern_2, 2:seq_pattern_3, 3:seq_pattern_4}\n",
    "check_file(filename, seq_pattern_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(old_file, cleaned_file):\n",
    "    \"\"\" Summary: \n",
    "            Part II: Main function for Exercise 1.4\n",
    "            Delete the detected exceptive lines from clean_file function\n",
    "            rewrite as a cleaned_file\n",
    "        Parameters:\n",
    "            old_file: relative path of the raw dummy data file\n",
    "            cleaned_file: relative path of the directory of rewritten data file\n",
    "        Returns:\n",
    "            printed information about deleted exceptive lines\n",
    "            generate a new cleaned_file \n",
    "    \"\"\"\n",
    "    with open(old_file) as infile, open(cleaned_file, 'w') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            if i != 45232 and i != 80337:\n",
    "                outfile.write(line)\n",
    "            if i == 45232 or i == 80337:\n",
    "                print(\"Line: {} was deleted\".format(line))\n",
    "\n",
    "old_file = '../data/dummy.fastq'\n",
    "cleaned_file = '../data/cleaned_file.fastq'\n",
    "clean_file(old_file, cleaned_file)\n",
    "print(\"New text file was saved as: cleaned_file.fastq.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__ Quality scores are encoded as ASCII characters with the lowest being \"!\" (which has ASCII code of 33) and the highest being \"I\" (which has ASCII code of 73).  Create a def which takes in the quality character and returns a number between 0 and 1 with 0 the lowest and 1 the highest.  The function should be a linear function of the ASCII code.  (Hint: check out the `chr` and `ord` built-in functions.)  Test it out on an arbitrary sequence from the data (you can just read in the first sequence if you like).  Add this to **def quality_score** in code/fastq_reader.py, as usual add a docstring describing the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``from fastq_reader import quality_score`` for checking if needed. \n",
    "\n",
    "**Example**: ``test_seq = 'A'\n",
    "q_score = quality_score(test_seq)\n",
    "print(\"The quality score of testing case {} = {}\".format(test_seq, q_score))``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastq_reader import quality_score\n",
    "\n",
    "test_seq = 'A'\n",
    "q_score = quality_score(test_seq)\n",
    "print(\"The quality score of testing case {} = {}\".format(test_seq, q_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__ Write a python script that iterates through the file, and for each sequence, calculates the average quality score (as defined above).  Have the script print the sequence with the highest average quality, lowest average quality.  Modify code/seq_quality.py and save it over the given template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: for exercise 3, print the identifier for the sequence (or called sequence name in exercise 7) instead of the sequence itself. \n",
    "\n",
    "**Note**: please run ``import seq_quality`` for checking if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seq_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report**: for this exercise, there are **428** highest sequences for average quality score, and only **1** lowest sequence for average quality score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4__ Write a python script that iterates through the file, and calculates the average quality of each of the 5 bases (A,T,G,C,N).  Print these to the screen as well, modify code/base_quality.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``import base_quality`` for checking if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 5__ In a sequence of tokens (such as characters in this case) an n-gram is a sequence of n tokens that follow one another in the sequence.  Fill **def ngram_freq** in code/fastq_reader.py which should take a sequence string and n as an input and output a dictionary.  This dictionary should have keys that are n-grams and values which are the frequency of that n-gram in the sequence (the percentage of all n-gram instances in the sequence which match a specific n-gram).  As an example, the 2-gram frequencies of the sequence \"TGTGCT\" are\n",
    "\n",
    "\"TG\": 2/5, \"GT\" : 1/5, \"GC\" : 1/5, \"CT\" : 1/5.\n",
    "\n",
    "Hint: it may be useful to use the Counter class in the collections package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``from fastq_reader import ngram_freq`` for checking if needed. \n",
    "\n",
    "**Example**: ``test = \"\"\n",
    "c = ngram_freq(test, 2)\n",
    "c``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastq_reader import ngram_freq\n",
    "\n",
    "test = \"NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\"\n",
    "c = ngram_freq(test, 2)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 6__ Fill in **def ngram_sim** which takes two sequences and outputs the following notion of similarity:\n",
    "$$\\sum_g \\sqrt{f(g) h(g)}$$\n",
    "where g are all n-grams in both sequences, f(g) is the frequency of g in the first sequence and h(g) is the frequency in the second.  Test this on an arbitrary pair of sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``from fastq_reader import ngram_sim`` for checking if needed. \n",
    "\n",
    "**Example**: ``seq1 = \"\"\n",
    "seq2 = \"\"\n",
    "sim_score = ngram_sim(seq1, seq2, 3)\n",
    "sim_score``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Testing Block for Exercise 6\n",
    "    seq1: first sequence in '../data/cleaned_file.fastq'\n",
    "    seq2: second sequence in '../data/cleaned_file.fastq'\n",
    "\"\"\"\n",
    "\n",
    "from fastq_reader import ngram_sim\n",
    "\n",
    "seq1 = \"NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\"\n",
    "seq2 = \"NATCTTGTACCACTCCTACTTCGCCGTCGTCTTCTCTCTCTGCTTGCACTCCGAGAGCGTCTGGCTGTGCTGTAGCTTTTAGTAGAAGGAGATCCAAAAGTCCAAGACGGAGACGATCTCATTCCCGAGAGAGGGGTAGAAGGTCAAGGAGCACATCCAA\"\n",
    "sim_score = ngram_sim(seq1, seq2, 3)\n",
    "sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 7__ Create a custom iterator that iterates through the file (line by line) and for each read should yield a tuple of (sequence name, sequence, quality) where each are strings.  Write over **def fastqReader** in the  code/fastq_reader.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``from fastq_reader import fastqReader`` for checking if needed. \n",
    "\n",
    "**Example**: ``fastq_iter = fastqReader(cleaned_file)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Testing Block for Exercise 7\n",
    "\"\"\"\n",
    "from fastq_reader import fastqReader\n",
    "fastq_iter = fastqReader(cleaned_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 8__ Use regular expression and the re package to do the following.  Write a new script in code/find_re.py that uses this iterator to read through the file and print to screen the sequence identifiers with the following characteristics:\n",
    "1. The longest continuous sequence of repeated \"TCC\"s.  For example \"AGTCCTCCTCCAG\" has 3 repeats.\n",
    "2. The most matches to G_G where _ is any base.\n",
    "3. The longest sequence of any one base, as in \"GTAAAAAAAGTA\" has a 7 As in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**: \n",
    "1. remember to print out the identifiers instead of the sequence itself\n",
    "2. When you are looking for TCC pattern, they can be adjacent or not\n",
    "3. when you are matching G_G pattern, they should not overlap with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: please run ``import find_re`` for checking if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import find_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
