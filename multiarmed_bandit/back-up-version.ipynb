{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1: another version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBandit:\n",
    "    '''\n",
    "    The bandit class you will use in this homework. DO NOT modify\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self._mu = np.array([-1.,-2.,1.5,0.5,-0.25,.75,.1,1.8,-3])\n",
    "        self._p = 1 / (1 + np.exp(-self._mu))\n",
    "        self.num_arms = len(self._mu)\n",
    "        self.total_rewards = np.zeros(len(self._mu))\n",
    "        \n",
    "    def pull(self,arms):\n",
    "        self.current_rewards = np.random.binomial(1,self._p)\n",
    "        self.total_rewards += self.current_rewards\n",
    "        return self.current_rewards[arms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy:\n",
    "    \"\"\"\n",
    "    Random policy, pure exploration. DO NOT modify\n",
    "    \"\"\"\n",
    "    def __init__(self, num_arms):\n",
    "        self.num_arms = num_arms\n",
    "        self.current_arm = None\n",
    "        \n",
    "    def select_arm(self):\n",
    "        \"\"\"\n",
    "        choose which arm to pull\n",
    "        \"\"\"\n",
    "        self.current_arm = np.random.randint(self.num_arms)\n",
    "        return self.current_arm\n",
    "    \n",
    "    def update_reward(self, reward):\n",
    "        \"\"\"\n",
    "        enter observed reward\n",
    "        \"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bak_run_trajectory(bandit, policies, T):\n",
    "    \"\"\"\n",
    "    Run T steps of bandit pulling each policy in each time step\n",
    "    \n",
    "    Arguments: \n",
    "    bandit: \n",
    "        a fresh instance of a Bandit class, \n",
    "        in this homework you will be always using an instance from RandomPolicy class\n",
    "    \n",
    "    policies:\n",
    "        a list like [policy1, policy2, policy3 ...]\n",
    "        each of the policy will have select_arm method and update_reward method\n",
    "    \n",
    "    Output: \n",
    "        regret of each policy in list, like\n",
    "        [regret1, regret2, ...]\n",
    "    \"\"\"\n",
    "    regrets_list = []  # per policy\n",
    "    i = 0  # policy index \n",
    "    for policy in policies:  # iterate all policies \n",
    "        bandit = SimpleBandit()  # reset the simulation\n",
    "        num_arms = policy.num_arms  # arms space in each policy \n",
    "        selected_arms = [policy.select_arm() for _ in range(T)]  # select random arm T times under each policy\n",
    "        print(f\"The {i}th policy selected these arms: {selected_arms} under {T} time steps\")\n",
    "        arms_current_rewards = [bandit.pull(arm) for arm in selected_arms]  # for a specific time step\n",
    "        actual_rewards = sum(arms_current_rewards)\n",
    "        print(f\"The current binary rewards for {T} arms: {arms_current_rewards}\")\n",
    "        print(f\"The actually rewards received from the {i}th pilicy: {actual_rewards}\")\n",
    "        print(f\"The potential total rewards under the {i}th policy for each arm: {bandit.total_rewards}\")\n",
    "        regret_i = np.amax(bandit.total_rewards) - actual_rewards\n",
    "        print(f\"The regrets under the {i}th policy: {regret_i}\")\n",
    "        regrets_list.append(regret_i)\n",
    "        i += 1\n",
    "    return regrets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th policy selected these arms: [2, 2, 2, 1, 1, 1, 2, 2, 1, 0, 0, 2, 1, 2, 2] under 15 time steps\n",
      "The current binary rewards for 15 arms: [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "The actually rewards received from the 0th pilicy: 7\n",
      "The potential total rewards under the 0th policy for each arm: [ 3.  0. 12.  6.  4. 13. 10. 14.  1.]\n",
      "The regrets under the 0th policy: 7.0\n",
      "The 1th policy selected these arms: [3, 0, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 0, 3, 3] under 15 time steps\n",
      "The current binary rewards for 15 arms: [1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n",
      "The actually rewards received from the 1th pilicy: 11\n",
      "The potential total rewards under the 1th policy for each arm: [ 4.  2. 14. 11.  5.  8.  9. 14.  1.]\n",
      "The regrets under the 1th policy: 3.0\n",
      "The 2th policy selected these arms: [3, 0, 3, 4, 4, 4, 3, 3, 4, 1, 1, 4, 2, 1, 2] under 15 time steps\n",
      "The current binary rewards for 15 arms: [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "The actually rewards received from the 2th pilicy: 5\n",
      "The potential total rewards under the 2th policy for each arm: [ 4.  4. 12.  7.  5. 13.  9. 15.  2.]\n",
      "The regrets under the 2th policy: 10.0\n",
      "[[7.0, 3.0, 10.0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.666666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" DEMO run_trajectory\n",
    "\"\"\"\n",
    "bandit = SimpleBandit()\n",
    "p1 = RandomPolicy(3)\n",
    "p2 = RandomPolicy(4)\n",
    "p3 = RandomPolicy(5)\n",
    "regrets = [bak_run_trajectory(SimpleBandit(), [p1, p2, p3], 15)] #for _ in range(10)]\n",
    "print(regrets)\n",
    "np.mean(regrets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
